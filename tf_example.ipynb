{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMROcGwHA8/BStnTSY3IJH3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW4mC5vU1cu9"
      },
      "source": [
        "# Tensorflow Practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fe9eI7g6WIh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEOtfut2zVPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d0f67b-767d-4be8-ed87-4a3299a6cc02"
      },
      "source": [
        "# check which tensorflow version\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loi-41Ic36s6"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LM8tSli38nS"
      },
      "source": [
        "observations = 1000\n",
        "\n",
        "# generate xs and zs\n",
        "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
        "zs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
        "\n",
        "generated_inputs = np.column_stack((xs, zs))\n",
        "\n",
        "noise = np.random.uniform(-1, 1, (observations,1))\n",
        "\n",
        "generated_targets = 2*xs - 3*zs + 5 + noise\n",
        "\n",
        "# save as numpy file since tensorflow prefers tensors as opposed to other files\n",
        "np.savez(\"tf_intro\", inputs=generated_inputs, targets=generated_targets)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt65nMqU6G1p"
      },
      "source": [
        "training_data = np.load('tf_intro.npz')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLqz4zPS6Xee"
      },
      "source": [
        "## Solving with Tensorflow\n",
        "**Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6LaULEkcw7n"
      },
      "source": [
        "# input size is for each variable, xs and zs\n",
        "input_size = 2\n",
        "\n",
        "output_size = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t08UrgNcdJmk",
        "outputId": "84110249-5a34-4513-f7c2-c9b48b07affb"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(output_size) # same as outputs = np.dot(inputs,weights) + bias\n",
        "                            ])\n",
        "\n",
        "# add optimizer, sgd for stochastic gradient descent\n",
        "# add L2 norm loss, aka least sum of squared errors\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "# now fit the model\n",
        "# epoch = number of iterations\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 - 0s - loss: 25.1304\n",
            "Epoch 2/100\n",
            "32/32 - 0s - loss: 4.5833\n",
            "Epoch 3/100\n",
            "32/32 - 0s - loss: 1.5287\n",
            "Epoch 4/100\n",
            "32/32 - 0s - loss: 0.6587\n",
            "Epoch 5/100\n",
            "32/32 - 0s - loss: 0.4264\n",
            "Epoch 6/100\n",
            "32/32 - 0s - loss: 0.3653\n",
            "Epoch 7/100\n",
            "32/32 - 0s - loss: 0.3456\n",
            "Epoch 8/100\n",
            "32/32 - 0s - loss: 0.3460\n",
            "Epoch 9/100\n",
            "32/32 - 0s - loss: 0.3537\n",
            "Epoch 10/100\n",
            "32/32 - 0s - loss: 0.3499\n",
            "Epoch 11/100\n",
            "32/32 - 0s - loss: 0.3420\n",
            "Epoch 12/100\n",
            "32/32 - 0s - loss: 0.3406\n",
            "Epoch 13/100\n",
            "32/32 - 0s - loss: 0.3378\n",
            "Epoch 14/100\n",
            "32/32 - 0s - loss: 0.3420\n",
            "Epoch 15/100\n",
            "32/32 - 0s - loss: 0.3415\n",
            "Epoch 16/100\n",
            "32/32 - 0s - loss: 0.3383\n",
            "Epoch 17/100\n",
            "32/32 - 0s - loss: 0.3403\n",
            "Epoch 18/100\n",
            "32/32 - 0s - loss: 0.3447\n",
            "Epoch 19/100\n",
            "32/32 - 0s - loss: 0.3506\n",
            "Epoch 20/100\n",
            "32/32 - 0s - loss: 0.3484\n",
            "Epoch 21/100\n",
            "32/32 - 0s - loss: 0.3480\n",
            "Epoch 22/100\n",
            "32/32 - 0s - loss: 0.3411\n",
            "Epoch 23/100\n",
            "32/32 - 0s - loss: 0.3422\n",
            "Epoch 24/100\n",
            "32/32 - 0s - loss: 0.3408\n",
            "Epoch 25/100\n",
            "32/32 - 0s - loss: 0.3376\n",
            "Epoch 26/100\n",
            "32/32 - 0s - loss: 0.3377\n",
            "Epoch 27/100\n",
            "32/32 - 0s - loss: 0.3412\n",
            "Epoch 28/100\n",
            "32/32 - 0s - loss: 0.3498\n",
            "Epoch 29/100\n",
            "32/32 - 0s - loss: 0.3394\n",
            "Epoch 30/100\n",
            "32/32 - 0s - loss: 0.3371\n",
            "Epoch 31/100\n",
            "32/32 - 0s - loss: 0.3449\n",
            "Epoch 32/100\n",
            "32/32 - 0s - loss: 0.3501\n",
            "Epoch 33/100\n",
            "32/32 - 0s - loss: 0.3377\n",
            "Epoch 34/100\n",
            "32/32 - 0s - loss: 0.3449\n",
            "Epoch 35/100\n",
            "32/32 - 0s - loss: 0.3430\n",
            "Epoch 36/100\n",
            "32/32 - 0s - loss: 0.3449\n",
            "Epoch 37/100\n",
            "32/32 - 0s - loss: 0.3392\n",
            "Epoch 38/100\n",
            "32/32 - 0s - loss: 0.3498\n",
            "Epoch 39/100\n",
            "32/32 - 0s - loss: 0.3432\n",
            "Epoch 40/100\n",
            "32/32 - 0s - loss: 0.3418\n",
            "Epoch 41/100\n",
            "32/32 - 0s - loss: 0.3428\n",
            "Epoch 42/100\n",
            "32/32 - 0s - loss: 0.3461\n",
            "Epoch 43/100\n",
            "32/32 - 0s - loss: 0.3408\n",
            "Epoch 44/100\n",
            "32/32 - 0s - loss: 0.3491\n",
            "Epoch 45/100\n",
            "32/32 - 0s - loss: 0.3429\n",
            "Epoch 46/100\n",
            "32/32 - 0s - loss: 0.3441\n",
            "Epoch 47/100\n",
            "32/32 - 0s - loss: 0.3379\n",
            "Epoch 48/100\n",
            "32/32 - 0s - loss: 0.3395\n",
            "Epoch 49/100\n",
            "32/32 - 0s - loss: 0.3466\n",
            "Epoch 50/100\n",
            "32/32 - 0s - loss: 0.3393\n",
            "Epoch 51/100\n",
            "32/32 - 0s - loss: 0.3387\n",
            "Epoch 52/100\n",
            "32/32 - 0s - loss: 0.3450\n",
            "Epoch 53/100\n",
            "32/32 - 0s - loss: 0.3408\n",
            "Epoch 54/100\n",
            "32/32 - 0s - loss: 0.3432\n",
            "Epoch 55/100\n",
            "32/32 - 0s - loss: 0.3392\n",
            "Epoch 56/100\n",
            "32/32 - 0s - loss: 0.3384\n",
            "Epoch 57/100\n",
            "32/32 - 0s - loss: 0.3480\n",
            "Epoch 58/100\n",
            "32/32 - 0s - loss: 0.3446\n",
            "Epoch 59/100\n",
            "32/32 - 0s - loss: 0.3391\n",
            "Epoch 60/100\n",
            "32/32 - 0s - loss: 0.3417\n",
            "Epoch 61/100\n",
            "32/32 - 0s - loss: 0.3513\n",
            "Epoch 62/100\n",
            "32/32 - 0s - loss: 0.3394\n",
            "Epoch 63/100\n",
            "32/32 - 0s - loss: 0.3452\n",
            "Epoch 64/100\n",
            "32/32 - 0s - loss: 0.3470\n",
            "Epoch 65/100\n",
            "32/32 - 0s - loss: 0.3390\n",
            "Epoch 66/100\n",
            "32/32 - 0s - loss: 0.3443\n",
            "Epoch 67/100\n",
            "32/32 - 0s - loss: 0.3435\n",
            "Epoch 68/100\n",
            "32/32 - 0s - loss: 0.3458\n",
            "Epoch 69/100\n",
            "32/32 - 0s - loss: 0.3368\n",
            "Epoch 70/100\n",
            "32/32 - 0s - loss: 0.3507\n",
            "Epoch 71/100\n",
            "32/32 - 0s - loss: 0.3411\n",
            "Epoch 72/100\n",
            "32/32 - 0s - loss: 0.3403\n",
            "Epoch 73/100\n",
            "32/32 - 0s - loss: 0.3430\n",
            "Epoch 74/100\n",
            "32/32 - 0s - loss: 0.3400\n",
            "Epoch 75/100\n",
            "32/32 - 0s - loss: 0.3422\n",
            "Epoch 76/100\n",
            "32/32 - 0s - loss: 0.3431\n",
            "Epoch 77/100\n",
            "32/32 - 0s - loss: 0.3401\n",
            "Epoch 78/100\n",
            "32/32 - 0s - loss: 0.3425\n",
            "Epoch 79/100\n",
            "32/32 - 0s - loss: 0.3372\n",
            "Epoch 80/100\n",
            "32/32 - 0s - loss: 0.3413\n",
            "Epoch 81/100\n",
            "32/32 - 0s - loss: 0.3448\n",
            "Epoch 82/100\n",
            "32/32 - 0s - loss: 0.3407\n",
            "Epoch 83/100\n",
            "32/32 - 0s - loss: 0.3395\n",
            "Epoch 84/100\n",
            "32/32 - 0s - loss: 0.3509\n",
            "Epoch 85/100\n",
            "32/32 - 0s - loss: 0.3437\n",
            "Epoch 86/100\n",
            "32/32 - 0s - loss: 0.3433\n",
            "Epoch 87/100\n",
            "32/32 - 0s - loss: 0.3471\n",
            "Epoch 88/100\n",
            "32/32 - 0s - loss: 0.3383\n",
            "Epoch 89/100\n",
            "32/32 - 0s - loss: 0.3380\n",
            "Epoch 90/100\n",
            "32/32 - 0s - loss: 0.3426\n",
            "Epoch 91/100\n",
            "32/32 - 0s - loss: 0.3458\n",
            "Epoch 92/100\n",
            "32/32 - 0s - loss: 0.3521\n",
            "Epoch 93/100\n",
            "32/32 - 0s - loss: 0.3437\n",
            "Epoch 94/100\n",
            "32/32 - 0s - loss: 0.3414\n",
            "Epoch 95/100\n",
            "32/32 - 0s - loss: 0.3459\n",
            "Epoch 96/100\n",
            "32/32 - 0s - loss: 0.3417\n",
            "Epoch 97/100\n",
            "32/32 - 0s - loss: 0.3459\n",
            "Epoch 98/100\n",
            "32/32 - 0s - loss: 0.3401\n",
            "Epoch 99/100\n",
            "32/32 - 0s - loss: 0.3418\n",
            "Epoch 100/100\n",
            "32/32 - 0s - loss: 0.3464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f894f022c10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaQkyHfrdJ8S"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}